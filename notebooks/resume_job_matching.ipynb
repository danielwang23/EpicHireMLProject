{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Resume into cleaned_Resume.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Resume Data:\n",
      "         ID                                         Resume_str  \\\n",
      "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
      "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
      "2  33176873           HR DIRECTOR       Summary      Over 2...   \n",
      "3  27018550           HR SPECIALIST       Summary    Dedica...   \n",
      "4  17812897           HR MANAGER         Skill Highlights  ...   \n",
      "\n",
      "                                         Resume_html Category  \n",
      "0  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "1  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "2  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "3  <div class=\"fontsize fontface vmargins hmargin...       HR  \n",
      "4  <div class=\"fontsize fontface vmargins hmargin...       HR  \n"
     ]
    }
   ],
   "source": [
    "resume_data = pd.read_csv('/Users/danielwang/EpicHire/Data-Science-Team/data/Resume.csv')\n",
    "print(\"Original Resume Data:\")\n",
    "print(resume_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned Resume Data:\n",
      "         ID                                         Resume_str Category\n",
      "0  16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...       HR\n",
      "1  22323967           HR SPECIALIST, US HR OPERATIONS      ...       HR\n",
      "2  33176873           HR DIRECTOR       Summary      Over 2...       HR\n",
      "3  27018550           HR SPECIALIST       Summary    Dedica...       HR\n",
      "4  17812897           HR MANAGER         Skill Highlights  ...       HR\n"
     ]
    }
   ],
   "source": [
    "# Clean the resume dataset to only include the Resume_str\n",
    "resume_data = resume_data[['ID', 'Resume_str', 'Category']]\n",
    "print(\"Cleaned Resume Data:\")\n",
    "print(resume_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered resume data saved to /Users/danielwang/EpicHire/Data-Science-Team/data/cleaned_Resume.csv\n"
     ]
    }
   ],
   "source": [
    "# Cleaned Resume\n",
    "filtered_resume_path = '/Users/danielwang/EpicHire/Data-Science-Team/data/cleaned_Resume.csv' \n",
    "resume_data.to_csv(filtered_resume_path, index=False)\n",
    "print(f\"Filtered resume data saved to {filtered_resume_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Begin Matching datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Descriptions Data:\n",
      "             Job Id                           Company  \\\n",
      "0  1089843540111562                 Icahn Enterprises   \n",
      "1   398454096642776      PNC Financial Services Group   \n",
      "2   481640072963533  United Services Automobile Assn.   \n",
      "3   688192671473044                              Hess   \n",
      "4   117057806156508                      Cairn Energy   \n",
      "\n",
      "                      Job Title Job Description Qualifications     Experience  \\\n",
      "0  Digital Marketing Specialist             NaN         M.Tech  5 to 15 Years   \n",
      "1                 Web Developer             NaN            BCA  2 to 12 Years   \n",
      "2            Operations Manager             NaN            PhD  0 to 12 Years   \n",
      "3              Network Engineer             NaN            PhD  4 to 11 Years   \n",
      "4                 Event Manager             NaN            MBA  1 to 12 Years   \n",
      "\n",
      "                        Role  \\\n",
      "0       Social Media Manager   \n",
      "1     Frontend Web Developer   \n",
      "2    Quality Control Manager   \n",
      "3  Wireless Network Engineer   \n",
      "4         Conference Manager   \n",
      "\n",
      "                                    Responsibilities  \\\n",
      "0  Manage and grow social media accounts, create ...   \n",
      "1  Design and code user interfaces for websites, ...   \n",
      "2  Establish and enforce quality control standard...   \n",
      "3  Design, configure, and optimize wireless netwo...   \n",
      "4  Specialize in conference and convention planni...   \n",
      "\n",
      "                                              skills  Work Type  \n",
      "0  Social media platforms (e.g., Facebook, Twitte...     Intern  \n",
      "1  HTML, CSS, JavaScript Frontend frameworks (e.g...     Intern  \n",
      "2  Quality control processes and methodologies St...  Temporary  \n",
      "3  Wireless network design and architecture Wi-Fi...  Full-Time  \n",
      "4  Event planning Conference logistics Budget man...     Intern  \n"
     ]
    }
   ],
   "source": [
    "# Job dataset loaded\n",
    "job_data = pd.read_csv('/Users/danielwang/EpicHire/Data-Science-Team/data/Technology_job_postings.csv')\n",
    "print(\"Job Descriptions Data:\")\n",
    "print(job_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keywords extracted for each job description:\n",
      "                      Job Title Job_Keywords\n",
      "0  Digital Marketing Specialist          nan\n",
      "1                 Web Developer          nan\n",
      "2            Operations Manager          nan\n",
      "3              Network Engineer          nan\n",
      "4                 Event Manager          nan\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# keywords = [\n",
    "#     'developer', 'engineer', 'data', 'software', 'it', 'analyst', 'system',\n",
    "#     'technician', 'programmer', 'social media', 'content', 'marketing',\n",
    "#     'network', 'database', 'design', 'management', 'security'\n",
    "# ]\n",
    "\n",
    "\n",
    "# def preprocess_text(text):\n",
    "#     words = str(text).lower().split()\n",
    "#     return \" \".join([word for word in words if word in keywords])\n",
    "\n",
    "def extract_keywords_from_description(description):\n",
    "    \"\"\"\n",
    "    Extracts keywords from the job description text by filtering out common stop words\n",
    "    and punctuation, leaving unique, meaningful words.\n",
    "    \"\"\"\n",
    "    # Basic text cleaning\n",
    "    words = re.findall(r'\\b\\w+\\b', str(description).lower())  # Find all word tokens and convert to lowercase\n",
    "    keywords = set(words)  # Use a set to store unique words\n",
    "    return \" \".join(keywords)  # Convert back to a space-separated string\n",
    "\n",
    "# Apply the function to extract keywords for each job in the job data\n",
    "job_data['Job_Keywords'] = job_data['Job Description'].apply(extract_keywords_from_description)\n",
    "print(\"Keywords extracted for each job description:\")\n",
    "print(job_data[['Job Title', 'Job_Keywords']].head())  # Display the first few rows for verification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Job Descriptions Data:\n",
      "             Job Id                     Job Title Job_Keywords\n",
      "0  1089843540111562  Digital Marketing Specialist             \n",
      "1   398454096642776                 Web Developer             \n",
      "2   481640072963533            Operations Manager             \n",
      "3   688192671473044              Network Engineer             \n",
      "4   117057806156508                 Event Manager             \n",
      "Processed Resume Data:\n",
      "         ID                                    Resume_Keywords\n",
      "0  16852973  management marketing marketing system manageme...\n",
      "1  22323967  system marketing content design software manag...\n",
      "2  33176873  management security security database manageme...\n",
      "3  27018550  management management management management da...\n",
      "4  17812897  management management data management manageme...\n"
     ]
    }
   ],
   "source": [
    "job_data['Job_Keywords'] = job_data['Job Description'].apply(preprocess_text)\n",
    "resume_data['Resume_Keywords'] = resume_data['Resume_str'].apply(preprocess_text)\n",
    "\n",
    "# Check results\n",
    "print(\"Processed Job Descriptions Data:\")\n",
    "print(job_data[['Job Id', 'Job Title', 'Job_Keywords']].head())\n",
    "\n",
    "print(\"Processed Resume Data:\")\n",
    "print(resume_data[['ID', 'Resume_Keywords']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dont run cell below code it is old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matching function to compare resumes with job descriptions\n",
    "def match_resumes_to_jobs(job_data, resume_data):\n",
    "    matches = []\n",
    "\n",
    "    # Vectorize the keywords to calculate similarity\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    job_tfidf = vectorizer.fit_transform(job_data['Job_Keywords'])\n",
    "    resume_tfidf = vectorizer.transform(resume_data['Resume_Keywords'])\n",
    "\n",
    "    # Calculate cosine similarity between each resume and job description\n",
    "    similarity_matrix = cosine_similarity(resume_tfidf, job_tfidf)\n",
    "\n",
    "    # Get the keywords in the vocabulary to help identify matches\n",
    "    vocab = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Identify the best match for each resume\n",
    "    for i, applicant_id in enumerate(resume_data['ID']):\n",
    "        best_match_index = similarity_matrix[i].argmax()\n",
    "        best_match_score = similarity_matrix[i][best_match_index]\n",
    "        \n",
    "        # Find matching keywords between resume and job description\n",
    "        resume_keywords = set(resume_data.loc[i, 'Resume_Keywords'].split())\n",
    "        job_keywords = set(job_data.loc[best_match_index, 'Job_Keywords'].split())\n",
    "        matching_keywords = resume_keywords.intersection(job_keywords)\n",
    "        \n",
    "        # Convert matching keywords to a comma-separated string\n",
    "        matching_keywords_str = \", \".join(matching_keywords)\n",
    "\n",
    "        # Store the match information\n",
    "        match_info = {\n",
    "            'Applicant Id': applicant_id,\n",
    "            'Matched Job Id': job_data.loc[best_match_index, 'Job Id'],\n",
    "            'Matched Job Title': job_data.loc[best_match_index, 'Job Title'],\n",
    "            'Match Score': best_match_score,\n",
    "            'Matching Keywords': matching_keywords_str  # Add matching keywords\n",
    "        }\n",
    "        matches.append(match_info)\n",
    "\n",
    "    # Return the results as a DataFrame\n",
    "    return pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run cell below instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def match_resumes_to_jobs(job_data, resume_data):\n",
    "    matches = []\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    # Transform job and resume keywords\n",
    "    job_tfidf = vectorizer.fit_transform(job_data['Job_Keywords'])\n",
    "    resume_tfidf = vectorizer.transform(resume_data['Resume_str'])  # Assuming resume text is in 'Resume_str'\n",
    "\n",
    "    # Calculate cosine similarity between each resume and job description\n",
    "    similarity_matrix = cosine_similarity(resume_tfidf, job_tfidf)\n",
    "    vocab = vectorizer.get_feature_names_out()  # Get feature names for matching\n",
    "\n",
    "    # Find the best match for each resume\n",
    "    for i, applicant_id in enumerate(resume_data['ID']):\n",
    "        best_match_index = similarity_matrix[i].argmax()\n",
    "        best_match_score = similarity_matrix[i][best_match_index]\n",
    "        \n",
    "        # Get the specific matching keywords by comparing transformed vectors\n",
    "        resume_keywords = set(resume_data.loc[i, 'Resume_str'].lower().split())\n",
    "        job_keywords = set(job_data.loc[best_match_index, 'Job_Keywords'].split())\n",
    "        matching_keywords = resume_keywords.intersection(job_keywords)\n",
    "        \n",
    "        matching_keywords_str = \", \".join(matching_keywords)\n",
    "\n",
    "        # Store the match information\n",
    "        match_info = {\n",
    "            'Applicant Id': applicant_id,\n",
    "            'Matched Job Id': job_data.loc[best_match_index, 'Job Id'],\n",
    "            'Matched Job Title': job_data.loc[best_match_index, 'Job Title'],\n",
    "            'Match Score': best_match_score,\n",
    "            'Matching Keywords': matching_keywords_str  # Display the matching keywords\n",
    "        }\n",
    "        matches.append(match_info)\n",
    "\n",
    "    # Return the results as a DataFrame\n",
    "    return pd.DataFrame(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resume-Job Matches:\n",
      "   Applicant Id    Matched Job Id                Matched Job Title  \\\n",
      "0      16852973   407980927519454                    HR Generalist   \n",
      "1      22323967  1343787400703296                       Copywriter   \n",
      "2      33176873   407980927519454                    HR Generalist   \n",
      "3      27018550  2122997813566133  Customer Service Representative   \n",
      "4      17812897   407980927519454                    HR Generalist   \n",
      "\n",
      "   Match Score                                  Matching Keywords  \n",
      "0     0.215434  training, programs, support, in, and, the, emp...  \n",
      "1     0.230886  materials, brand, campaigns, creative, and, co...  \n",
      "2     0.262458  training, support, provide, in, and, the, empl...  \n",
      "3     0.224830  calls, a, over, call, and, experience, custome...  \n",
      "4     0.332669  in, and, such, hr, training, to, various, prov...  \n"
     ]
    }
   ],
   "source": [
    "# Running matching and show results\n",
    "matches_df = match_resumes_to_jobs(job_data, resume_data)\n",
    "print(\"Resume-Job Matches:\")\n",
    "print(matches_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matches saved to resume_job_matches.csv\n"
     ]
    }
   ],
   "source": [
    "# Saving matches to a csv file\n",
    "matches_df.to_csv('/Users/danielwang/EpicHire/Data-Science-Team/data/resume_job_matches.csv', index=False)\n",
    "print(\"Matches saved to resume_job_matches.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
